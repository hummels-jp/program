{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d62b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\AppData\\Local\\Temp\\ipykernel_30856\\2236993598.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "C:\\Users\\chang\\AppData\\Local\\Temp\\ipykernel_30856\\2236993598.py:14: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = llm.predict(\"介绍下你自己\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！我是一个由OpenAI开发的人工智能助手，旨在帮助用户回答问题、提供信息和解决问题。我可以处理各种主题，包括科学、技术、文化、历史等。如果你有任何问题或需要帮助，随时可以问我！\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_PROXY\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",  # 使用最新的 GPT-4o 模型\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    ")\n",
    "\n",
    "result = llm.predict(\"介绍下你自己\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf161ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 男孩：铁柱\n",
      "2. 女孩：玉兰\n",
      "3. 男孩：龙飞\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "# 获取环境变量\n",
    "api_base = os.getenv(\"OPENAI_PROXY\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 初始化 OpenAI 模型\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",  # 使用 GPT-3.5 Turbo Instruct 模型\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    ")\n",
    "\n",
    "# 定义 PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"你是一个起名大师，请模仿示例起3个{county}名字，比如男孩经常被叫做{boy}，女孩经常被叫做{girl}：\"\n",
    ")\n",
    "\n",
    "# 格式化 PromptTemplate\n",
    "message = prompt.format(county=\"中国传统的\", boy=\"狗蛋\", girl=\"翠花\")\n",
    "\n",
    "# 调用模型生成结果\n",
    "result = llm.predict(message)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f87c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'bye']\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "# 自定义类，继承了 BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "# 测试自定义解析器\n",
    "result = CommaSeparatedListOutputParser().parse(\"hi, bye\")\n",
    "print(result)  # 输出 ['hi', 'bye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da952e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你是一个算命大师，帮我起1个具有法国特色的男孩名字'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符模板\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name}，帮我起1个具有{county}特色的男孩名字\")\n",
    "prompt.format(name=\"算命大师\", county=\"法国\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6580acf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师。你的名字叫陈大师。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你好陈大师，你觉得如何？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='你好！我状态非常好！', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你叫什么名字呢？', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对话模板具有结构，chatmodels\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师。你的名字叫{name}。\"),\n",
    "        (\"human\", \"你好{name}，你觉得如何？\"),\n",
    "        (\"ai\", \"你好！我状态非常好！\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template.format_messages(name=\"陈大师\", user_input=\"你叫什么名字呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9885bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名：': '陈瞳子'}, response_metadata={}),\n",
       " HumanMessage(content='请问大师叫什么？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='我叫陈瞳子', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "sy = SystemMessage(\n",
    "    content=\"你是一个起名大师\",\n",
    "    additional_kwargs={\"大师姓名：\": \"陈瞳子\"}\n",
    ")\n",
    "\n",
    "hu = HumanMessage(\n",
    "    content=\"请问大师叫什么？\"\n",
    ")\n",
    "\n",
    "ai = AIMessage(\n",
    "    content=\"我叫陈瞳子\"\n",
    ")\n",
    "\n",
    "[sy, hu, ai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a97a30d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='愿原力与你同在！', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"愿{subject}与你同在！\"\n",
    "\n",
    "chat_message_prompt = HumanMessagePromptTemplate.from_template(template=prompt)\n",
    "chat_message_prompt.format(subject=\"原力\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2f37b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一个非常有经验和天赋的程序员，现在会给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
      "函数名称: hello_world\n",
      "源代码:\n",
      "def hello_world(a: int, b: int):\n",
      "    if a > b:\n",
      "        return a\n",
      "    else:\n",
      "        return b\n",
      "\n",
      "代码解释：\n",
      "\n",
      "函数名称：hello_world\n",
      "源代码：\n",
      "def hello_world(a: int, b: int):\n",
      "    if a > b:\n",
      "        return a\n",
      "    else:\n",
      "        return b\n",
      "\n",
      "中文解释：\n",
      "这是一个名为hello_world的函数，它接受两个整数参数a和b。如果a大于b，则返回a，否则返回b。\n"
     ]
    }
   ],
   "source": [
    "##函数大师：根据函数名称，查找函数代码，并给出中文的代码说明\n",
    "\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "# 定义一个简单的函数作为示例效果\n",
    "def hello_world(a: int, b: int):\n",
    "    if a > b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "你是一个非常有经验和天赋的程序员，现在会给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "函数名称: {function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释：\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    # 获取源代码\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "# 自定义的模板类\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获取源代码\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "\n",
    "        # 生成提示词模板\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__, source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "print(pm)\n",
    "\n",
    "\n",
    "# 和LLM连接起来\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "api_base = os.getenv(\"OPENAI_PROXY\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    ")\n",
    "\n",
    "msg = llm.predict(pm)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93c2c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n给我讲一个关于翠花的爱情伤故事\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##f-string是python内置的一种模板引擎\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "fstring_template = '''\n",
    "给我讲一个关于{name}的{what}故事\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(fstring_template)\n",
    "\n",
    "prompt.format(name=\"翠花\", what=\"爱情伤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b26af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'给我讲一个关于狗剩的高兴故事'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Jinja2是一个灵活、高效的Python模板引擎，可以方便地生成各种标记格式的文档。\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jinja2_template = \"给我讲一个关于{{name}}的{{what}}故事\"\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "prompt.format(name=\"狗剩\", what=\"高兴\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
